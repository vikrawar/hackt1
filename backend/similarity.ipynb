{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47ec447-63fb-4ee1-af23-760e79611990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikas/miniforge3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/vikas/miniforge3/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/vikas/miniforge3/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <8B7B82B6-E557-3363-B7AC-84C29F398EBA> /Users/vikas/miniforge3/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/vikas/miniforge3/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/vikas/miniforge3/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Path to the folder containing .txt files\n",
    "folder_path = 'pdfs'\n",
    "\n",
    "# Read all .txt files and store the content\n",
    "file_contents = []\n",
    "file_names = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            file_contents.append(f.read())\n",
    "        file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48eac9f0-ceb4-479f-a394-b26c659effd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0607af8-06f0-414d-8242-b683252db872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert file contents to embeddings\n",
    "embeddings = model.encode(file_contents)\n",
    "\n",
    "# Convert embeddings to float32\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# Create a FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance\n",
    "index.add(embeddings)\n",
    "\n",
    "# Perform similarity search (e.g., find the closest match)\n",
    "query = \"What is the zoning district and permissible use for this address?\"\n",
    "query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "# Search the index\n",
    "D, I = index.search(query_embedding, 1)  # Top 1 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838468e7-6c3d-44c3-a099-54e805da6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Content: {file_contents[I[0][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b23ac-fdf3-43c2-a299-9eda8d2f4fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
